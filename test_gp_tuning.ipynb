{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8baa94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "from scalable_gp_inference.hparam_training import train_exact_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35eac6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f91c3fab8d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c35c3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(\"cuda:1\")\n",
    "n = 10000\n",
    "d = 3\n",
    "\n",
    "# Training data is n points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, n).unsqueeze(1).expand(-1, d)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "freqs = 2 * torch.pi * torch.randn(d)\n",
    "train_y = torch.sin(train_x @ freqs) + \\\n",
    "    torch.randn(train_x.shape[0]) * (0.04 ** 0.5)\n",
    "\n",
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7304378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3410016050517224\n",
      "tensor([[0.6043, 0.6043, 0.6043]], device='cuda:1')\n",
      "0.041294909693002424\n"
     ]
    }
   ],
   "source": [
    "hparams = train_exact_gp(train_x, train_y, \"rbf\", {\"lr\": 0.1}, 100)\n",
    "print(hparams.signal_variance)\n",
    "print(hparams.kernel_lengthscale)\n",
    "print(hparams.noise_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ac3d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.682003210103445\n",
      "tensor([[1.2086, 1.2086, 1.2086]], device='cuda:1')\n",
      "0.08258981938600485\n"
     ]
    }
   ],
   "source": [
    "hparams_doubled = hparams + hparams\n",
    "print(hparams_doubled.signal_variance)\n",
    "print(hparams_doubled.kernel_lengthscale)\n",
    "print(hparams_doubled.noise_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9936123a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPHparams(signal_variance=0.4470005350172408, kernel_lengthscale=tensor([[0.2014, 0.2014, 0.2014]], device='cuda:1'), noise_variance=0.013764969897667475)\n",
      "GPHparams(signal_variance=0.4470005350172408, kernel_lengthscale=tensor([[0.2014, 0.2014, 0.2014]], device='cuda:1'), noise_variance=0.013764969897667475)\n"
     ]
    }
   ],
   "source": [
    "print(hparams / 3)\n",
    "print(hparams / 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b68287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ExactGPModel(gpytorch.models.ExactGP):\n",
    "#     def __init__(self, train_x, train_y, likelihood, base_kernel):\n",
    "#         super().__init__(train_x, train_y, likelihood)\n",
    "#         self.mean_module = gpytorch.means.ConstantMean()\n",
    "#         self.covar_module = gpytorch.kernels.ScaleKernel(base_kernel)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         mean_x = self.mean_module(x)\n",
    "#         covar_x = self.covar_module(x)\n",
    "#         return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f26ccead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize likelihood and model\n",
    "# likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "# # base_kernel = gpytorch.kernels.RBFKernel(ard_num_dims=d)\n",
    "# base_kernel = gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=d)\n",
    "# model = ExactGPModel(train_x, train_y, likelihood, base_kernel)\n",
    "# model = model.to(device)\n",
    "# likelihood = likelihood.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26fe459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find optimal model hyperparameters\n",
    "# model.train()\n",
    "# likelihood.train()\n",
    "\n",
    "# # Use the Adam optimizer\n",
    "# # Includes GaussianLikelihood parameters\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# # \"Loss\" for GPs - the marginal log likelihood\n",
    "# mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "# training_iter = 100\n",
    "# for i in range(training_iter):\n",
    "#     # Zero gradients from previous iteration\n",
    "#     optimizer.zero_grad()\n",
    "#     # Output from model\n",
    "#     output = model(train_x)\n",
    "#     # Calc loss and backprop gradients\n",
    "#     loss = -mll(output, train_y)\n",
    "#     loss.backward()\n",
    "#     print(f'Iter {i+1}/{training_iter} - Loss: {loss.item():.3f}   signal: {model.covar_module.outputscale.item():.3f}   '\n",
    "#         f'lengthscale: {model.covar_module.base_kernel.lengthscale.detach().cpu().numpy()}   '\n",
    "#         f'noise: {model.likelihood.noise.item():.3f}')\n",
    "#     optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp_inference_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
