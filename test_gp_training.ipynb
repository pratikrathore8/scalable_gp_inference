{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baa94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from scalable_gp_inference.hparam_training import _train_exact_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35eac6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f51cc0eb9d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c35c3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(\"cuda:1\")\n",
    "n = 10000\n",
    "d = 3\n",
    "\n",
    "# Training data is n points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, n).unsqueeze(1).expand(-1, d)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "freqs = 2 * torch.pi * torch.randn(d)\n",
    "train_y = torch.sin(train_x @ freqs) + \\\n",
    "    torch.randn(train_x.shape[0]) * (0.04 ** 0.5)\n",
    "\n",
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7304378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3410016050517224\n",
      "tensor([0.6043, 0.6043, 0.6043], device='cuda:1')\n",
      "0.041294909693002424\n"
     ]
    }
   ],
   "source": [
    "hparams = _train_exact_gp(train_x, train_y, \"rbf\", {\"lr\": 0.1}, 100)\n",
    "print(hparams.signal_variance)\n",
    "print(hparams.kernel_lengthscale)\n",
    "print(hparams.noise_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ac3d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.682003210103445\n",
      "tensor([1.2086, 1.2086, 1.2086], device='cuda:1')\n",
      "0.08258981938600485\n"
     ]
    }
   ],
   "source": [
    "hparams_doubled = hparams + hparams\n",
    "print(hparams_doubled.signal_variance)\n",
    "print(hparams_doubled.kernel_lengthscale)\n",
    "print(hparams_doubled.noise_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9936123a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPHparams(signal_variance=0.4470005350172408, kernel_lengthscale=tensor([0.2014, 0.2014, 0.2014], device='cuda:1'), noise_variance=0.013764969897667475)\n",
      "GPHparams(signal_variance=0.4470005350172408, kernel_lengthscale=tensor([0.2014, 0.2014, 0.2014], device='cuda:1'), noise_variance=0.013764969897667475)\n"
     ]
    }
   ],
   "source": [
    "print(hparams / 3)\n",
    "print(hparams / 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80ea469c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPHparams(signal_variance=1.3410016050517224, kernel_lengthscale=tensor([0.6043, 0.6043, 0.6043]), noise_variance=0.041294909693002424)\n"
     ]
    }
   ],
   "source": [
    "print(hparams.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1415126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e069e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPHparams(signal_variance=1.3410016050517224, kernel_lengthscale=tensor([0.6043, 0.6043, 0.6043]), noise_variance=0.041294909693002424)\n"
     ]
    }
   ],
   "source": [
    "with open(\"hparam.pkl\", \"wb\") as f:\n",
    "    pickle.dump(hparams.to(\"cpu\"), f)\n",
    "with open(\"hparam.pkl\", \"rb\") as f:\n",
    "    hparams_loaded = pickle.load(f)\n",
    "\n",
    "print(hparams_loaded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp_inference_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
